{
    "seed": 321,
    "task": "webnlg",
    "model_name": "gpt2",
    "model_checkpoint": "runs/Dec23_13-58-06_idealab-02_inducer-mam_webnlg_0.0025_epoch2",
    "n_epochs": 2,
    "train_batch_size": 8,
    "valid_batch_size": 8,
    "gradient_accumulation_steps": 1,
    "lr": 0.0025,
    "patience": 5,
    "non_linearity": "relu",
    "label_smooth": 0.1,
    "add_adapter_in_self_attention": false,
    "add_adapter_in_feed_forward": true,
    "add_layer_norm_before_adapter": true,
    "add_layer_norm_after_adapter": false,
    "adapter_config_name": "adapter",
    "train_task_adapters": true,
    "task_reduction_factor": 18.2,
    "parallel_adapter": "Lin",
    "truncated_gaussian_initialization": false,
    "prefix_tuning": "landmark",
    "prefix_length": 3,
    "prefix_dim": 7,
    "prefix_value_extension": true,
    "prefix_head_share": false,
    "lora": "Q",
    "lora_alpha": 32.0,
    "lora_Q_rank": 16,
    "lora_dropout": 0.1,
    "lora_ini": "He",
    "unfreeze_lm_head": false,
    "unfreeze_layer_norms": false,
    "unfreeze_task_embeddings": true
}